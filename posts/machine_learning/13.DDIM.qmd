---
title: "DDIM"
author: "Qingsen Zhang"
date: "2025-11-20"
categories: ['Python', 'Diffusion']
description: 'Understanding DDIM step by step'
format: 
  html:
    code-fold: true
execute: 
  message: false
  warning: false
editor_options: 
  chunk_output_type: console
---

# DDPM Forward Backword and Loss

## Introduction

This document provides a one step simple implementation of the **<span style="color:#188038">Denoising Diffusion Implicit Models</span> (DDPM)** algorithm.  
This document is based on the paper [Denoising Diffusion Implicit Models](https://arxiv.org/pdf/2010.02502 "ICLR2021").  

$$
x_t = √α_t * x_0 + √(1 - α_t) * ε_t, \text{ where } ε_t ~ N(0, I)
$$


> ![Diffusion process illustration](https://huggingface.co/blog/assets/78_annotated-diffusion/diffusion_figure.png)   

Based on the figure, let's define some variables here:  
- The actual image $x_0$

- The <span style="color:#188038">defined</span> total timesteps $T$

- One specific timestep $t$.

- The pure noise $x_T$

- $q(x_t | x_{t-1})$ is the distrubition of $x_t$ given $x_{t-1}$

- $p(x_{t-1} | x_{t})$ is the distrubition of $x_{t-1}$ given $x_{t}$


### 1. **Forward** Process
Assume we have $q(x_0)$ is the distribution for real data, we get $x_0$ could be sampled from $q(x_0)$, denoted as $x_0 \sim q(x_0)$.  
The forward process $q(x_t | x_{t-1})$ gradually adds Gaussian noise at each timestep $t$.  
We can write:
$$  
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t\mathbf{I}) 
$$  
Where $\beta_t$ is the variance schedule.

### 2. **Backword** Process

### 3. **Loss**  

```{python}

# Import necessary libraries

```
### Forword process
```{python}
# forward
```
### Backword process
```{python}
# backword
```


prev [DDPM](./12.DDPM.qmd)  
next [Ractified Flow](./14.Rectified_Flow.qmd)  
[go back](./machine_learning.qmd) 
